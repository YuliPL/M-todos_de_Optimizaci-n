import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
import itertools
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# === CONFIGURACI√ìN GENERAL ===
sns.set(style="whitegrid")
plt.rcParams.update({'figure.max_open_warning': 0})

# Rutas necesarias - AJUSTA ESTAS RUTAS SEG√öN TU SISTEMA
ruta_base = r"c:\INGENIERIA ESTADISTICA E INFORMATICA - UNAP\QUINTO SEMESTRE\METODOS DE OPTIMIZACION\PORTAFOLIO\Articulo Cientifico\datos_bcrp\base_normalizada.csv"
ruta_base_unificada = r"c:\INGENIERIA ESTADISTICA E INFORMATICA - UNAP\QUINTO SEMESTRE\METODOS DE OPTIMIZACION\PORTAFOLIO\Articulo Cientifico\datos_bcrp\base_unificada.csv"
carpeta_salida = r"c:\INGENIERIA ESTADISTICA E INFORMATICA - UNAP\QUINTO SEMESTRE\METODOS DE OPTIMIZACION\PORTAFOLIO\Articulo Cientifico\resultados"
os.makedirs(carpeta_salida, exist_ok=True)

# Tasa libre de riesgo mensual (aproximaci√≥n: 3% anual = 0.25% mensual)
RISK_FREE_RATE_MONTHLY = 0.0025
RISK_FREE_RATE_ANNUAL = 0.03

print("üöÄ INICIANDO AN√ÅLISIS COMPLETO DE Q-LEARNING PARA PORTAFOLIOS")
print("="*80)

# Carga de datos unificada
print("üìä Cargando datos macroecon√≥micos...")
df_explora = pd.read_csv(ruta_base_unificada, parse_dates=["fecha"]).dropna()
print(f"   ‚úÖ Datos cargados: {len(df_explora)} observaciones desde {df_explora['fecha'].min()} hasta {df_explora['fecha'].max()}")

# =====================================================================
# AN√ÅLISIS EXPLORATORIO INICIAL
# =====================================================================

print("\nüìà Generando an√°lisis exploratorio...")

# 1. Serie temporal
plt.figure(figsize=(12, 6))
for col in ['IPC', 'PBI', 'RIN', 'Tasa_Interbancaria', 'Tipo_Cambio', 'BVL']:
    plt.plot(df_explora['fecha'], df_explora[col], label=col)
plt.title('Evoluci√≥n de Indicadores Macroecon√≥micos (2015‚Äì2024)')
plt.xlabel('Fecha'); plt.ylabel('Valor')
plt.legend(); plt.tight_layout()
plt.savefig(os.path.join(carpeta_salida, "serie_tiempo_macroeconomica.png"))
plt.close()

# 2. Correlaci√≥n
plt.figure(figsize=(8, 6))
sns.heatmap(df_explora.drop(columns='fecha').corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Matriz de Correlaci√≥n de Variables Macroecon√≥micas')
plt.tight_layout()
plt.savefig(os.path.join(carpeta_salida, "correlacion_macroeconomica.png"))
plt.close()

# 3. Histogramas
fig, axs = plt.subplots(2, 3, figsize=(15, 8))
for i, col in enumerate(['IPC', 'PBI', 'RIN', 'Tasa_Interbancaria', 'Tipo_Cambio', 'BVL']):
    sns.histplot(df_explora[col], kde=True, ax=axs.flatten()[i])
    axs.flatten()[i].set_title(f'Distribuci√≥n: {col}')
fig.tight_layout()
plt.savefig(os.path.join(carpeta_salida, "histogramas_macroeconomicos.png"))
plt.close()

# =====================================================================
# PREPARACI√ìN DE DATOS PARA Q-LEARNING
# =====================================================================

print("\nü§ñ Preparando datos para entrenamiento Q-Learning...")
df = pd.read_csv(ruta_base).dropna()
df['fecha'] = pd.to_datetime(df['fecha'])
variables = ['IPC', 'PBI', 'Tipo_Cambio', 'Tasa_Interbancaria', 'RIN', 'BVL']
estados = df[variables].values

# Definir acciones con pesos de riesgo m√°s realistas
acciones = {0: 'Conservador', 1: 'Moderado', 2: 'Agresivo', 3: 'Mantener'}
pesos_riesgo = {0: 0.3, 1: 0.6, 2: 1.0, 3: 0.6}  # Conservador menos riesgo

print(f"   ‚úÖ Estados preparados: {len(estados)} per√≠odos, {len(variables)} variables")
print(f"   ‚úÖ Acciones definidas: {len(acciones)} estrategias")

# =====================================================================
# FUNCI√ìN DE ENTRENAMIENTO Q-LEARNING
# =====================================================================

def entrenar_q_learning(alpha, gamma, epsilon_decay, episodios=500, verbose=False):
    """Entrena modelo Q-Learning con hiperpar√°metros espec√≠ficos"""
    Q = defaultdict(lambda: np.zeros(len(acciones)))
    epsilon = 1.0
    epsilon_min = 0.01
    
    recompensas_episodio = []
    
    for ep in range(episodios):
        recompensa_total = 0
        for t in range(len(estados)-1):
            estado_actual = tuple(np.round(estados[t], 3))  # Redondear para discretizar
            estado_siguiente = tuple(np.round(estados[t+1], 3))
            
            # Selecci√≥n de acci√≥n (Œµ-greedy)
            if np.random.rand() < epsilon:
                accion = np.random.choice(list(acciones.keys()))
            else:
                accion = np.argmax(Q[estado_actual])
            
            # Calcular recompensa
            delta_bvl = estados[t+1][5] - estados[t][5]
            r = pesos_riesgo[accion] * delta_bvl
            
            # Actualizar Q-value
            Q[estado_actual][accion] += alpha * (r + gamma * np.max(Q[estado_siguiente]) - Q[estado_actual][accion])
            
            recompensa_total += r
        
        # Decaimiento de epsilon
        epsilon = max(epsilon * epsilon_decay, epsilon_min)
        recompensas_episodio.append(recompensa_total)
        
        if verbose and ep % 100 == 0:
            print(f"Episodio {ep}: Recompensa = {recompensa_total:.4f}, Epsilon = {epsilon:.4f}")
    
    return Q, recompensas_episodio

# =====================================================================
# ENTRENAMIENTO INICIAL CON HIPERPAR√ÅMETROS BASE
# =====================================================================

print("\nüéØ Entrenando modelo Q-Learning con hiperpar√°metros base...")

# Hiperpar√°metros optimizados iniciales
alpha, gamma, epsilon_decay = 0.1, 0.95, 0.995
episodios = 500

# Entrenamiento inicial
Q_base, recompensas_episodio = entrenar_q_learning(alpha, gamma, epsilon_decay, episodios, verbose=True)

print("‚úÖ Entrenamiento base completado")

# Curva de aprendizaje
plt.figure(figsize=(10, 4))
plt.plot(recompensas_episodio)
plt.title("Curva de Aprendizaje del Agente RL (Configuraci√≥n Base)")
plt.xlabel("Episodio"); plt.ylabel("Recompensa Total")
plt.tight_layout()
plt.savefig(os.path.join(carpeta_salida, "curva_aprendizaje_rl_base.png"))
plt.close()

# =====================================================================
# SIMULACI√ìN CON ESTRATEGIAS
# =====================================================================

def simular_estrategias(Q_modelo):
    """Simula todas las estrategias de inversi√≥n"""
    
    # Preparar datos para simulaci√≥n
    df_sim = df.copy()
    df_sim["accion_rl"] = ""
    df_sim["valor_RL"] = 1.0

    # Simulaci√≥n Q-Learning
    for i in range(1, len(estados)):
        estado_actual = tuple(np.round(estados[i-1], 3))
        accion = np.argmax(Q_modelo[estado_actual])
        df_sim.loc[i, "accion_rl"] = acciones[accion]
        
        # Calcular rendimiento basado en BVL real (no normalizado)
        bvl_actual = df_explora.iloc[i-1]['BVL']
        bvl_siguiente = df_explora.iloc[i]['BVL']
        rendimiento_bvl = (bvl_siguiente - bvl_actual) / bvl_actual
        
        peso = pesos_riesgo[accion]
        rendimiento_ajustado = peso * rendimiento_bvl
        
        df_sim.loc[i, "valor_RL"] = df_sim.loc[i-1, "valor_RL"] * (1 + rendimiento_ajustado)

    # === BENCHMARKS CORREGIDOS ===

    # 1. Buy & Hold CORREGIDO (simplemente el √≠ndice BVL)
    bvl_inicial = df_explora.iloc[0]['BVL']
    df_sim["BuyHold"] = df_explora['BVL'] / bvl_inicial

    # 2. Agente Aleatorio
    np.random.seed(42)  # Para reproducibilidad
    df_sim["Aleatorio"] = 1.0
    for i in range(1, len(df_sim)):
        accion_aleatoria = np.random.choice(list(acciones.keys()))
        bvl_actual = df_explora.iloc[i-1]['BVL']
        bvl_siguiente = df_explora.iloc[i]['BVL']
        rendimiento_bvl = (bvl_siguiente - bvl_actual) / bvl_actual
        peso = pesos_riesgo[accion_aleatoria]
        rendimiento_ajustado = peso * rendimiento_bvl
        df_sim.loc[i, "Aleatorio"] = df_sim.loc[i-1, "Aleatorio"] * (1 + rendimiento_ajustado)

    # 3. Estrategia Markowitz MEJORADA (pesos optimizados simples)
    df_sim["Markowitz"] = 1.0
    for i in range(1, len(df_sim)):
        bvl_actual = df_explora.iloc[i-1]['BVL']
        bvl_siguiente = df_explora.iloc[i]['BVL']
        rendimiento_bvl = (bvl_siguiente - bvl_actual) / bvl_actual
        
        # Portfolio: 60% BVL + 40% risk-free
        rendimiento_portfolio = 0.6 * rendimiento_bvl + 0.4 * RISK_FREE_RATE_MONTHLY
        df_sim.loc[i, "Markowitz"] = df_sim.loc[i-1, "Markowitz"] * (1 + rendimiento_portfolio)
    
    return df_sim

print("\nüìä Simulando estrategias de inversi√≥n...")
df_sim_base = simular_estrategias(Q_base)

# =====================================================================
# FUNCI√ìN DE M√âTRICAS FINANCIERAS
# =====================================================================

def calcular_metricas(serie, nombre):
    """Calcula m√©tricas financieras corregidas"""
    # Convertir a numpy array y limpiar
    valores = np.array(serie.dropna())
    if len(valores) < 2:
        return {"Estrategia": nombre, "Error": "Datos insuficientes"}
    
    # Calcular rendimientos
    rendimientos = np.diff(valores) / valores[:-1]
    rendimientos = rendimientos[np.isfinite(rendimientos)]
    
    if len(rendimientos) == 0:
        return {"Estrategia": nombre, "Error": "No hay rendimientos v√°lidos"}
    
    # M√©tricas anualizadas
    rendimiento_promedio_mensual = np.mean(rendimientos)
    rendimiento_anual = (1 + rendimiento_promedio_mensual) ** 12 - 1
    
    volatilidad_mensual = np.std(rendimientos)
    volatilidad_anual = volatilidad_mensual * np.sqrt(12)
    
    # Sharpe ratio corregido (con tasa libre de riesgo)
    excess_return = rendimiento_anual - RISK_FREE_RATE_ANNUAL
    sharpe_ratio = excess_return / volatilidad_anual if volatilidad_anual > 0 else 0
    
    # Drawdown m√°ximo
    valores_acum = np.cumprod(1 + rendimientos)
    peak = np.maximum.accumulate(valores_acum)
    drawdown = (valores_acum - peak) / peak
    max_drawdown = np.min(drawdown)
    
    # Retorno total
    retorno_total = (valores[-1] / valores[0]) - 1
    
    return {
        "Estrategia": nombre,
        "Rendimiento Anual": rendimiento_anual,
        "Volatilidad": volatilidad_anual,
        "Sharpe Ratio": sharpe_ratio,
        "Max Drawdown": max_drawdown,
        "Retorno Total": retorno_total
    }

# Calcular m√©tricas para estrategia base
estrategias = ["valor_RL", "BuyHold", "Markowitz", "Aleatorio"]
nombres = ["Q-Learning", "Buy & Hold", "Markowitz", "Agente Aleatorio"]

tabla_metricas_base = []
for estrategia, nombre in zip(estrategias, nombres):
    metricas = calcular_metricas(df_sim_base[estrategia], nombre)
    tabla_metricas_base.append(metricas)

df_resultados_base = pd.DataFrame(tabla_metricas_base)
print("\n=== M√âTRICAS BASE (CONFIGURACI√ìN INICIAL) ===")
print(df_resultados_base.round(4))

# =====================================================================
# AN√ÅLISIS DE SENSIBILIDAD DE HIPERPAR√ÅMETROS
# =====================================================================

def analisis_sensibilidad():
    """Realiza an√°lisis exhaustivo de sensibilidad de hiperpar√°metros"""
    print("\nüîç Iniciando an√°lisis de sensibilidad de hiperpar√°metros...")
    
    # Rangos de hiperpar√°metros para evaluar
    alphas = [0.05, 0.1, 0.2, 0.3]
    gammas = [0.9, 0.95, 0.99]
    decays = [0.99, 0.995, 0.999]
    
    resultados_sensibilidad = []
    
    # Grid search completo
    total_combinaciones = len(alphas) * len(gammas) * len(decays)
    contador = 0
    
    for alpha_test, gamma_test, decay_test in itertools.product(alphas, gammas, decays):
        contador += 1
        print(f"   Evaluando {contador}/{total_combinaciones}: Œ±={alpha_test}, Œ≥={gamma_test}, decay={decay_test}")
        
        # Entrenar m√∫ltiples veces para obtener estad√≠sticas robustas
        rendimientos_config = []
        sharpe_ratios = []
        
        for semilla in range(3):  # 3 entrenamientos por combinaci√≥n
            np.random.seed(semilla + contador)
            Q_temp, recompensas_temp = entrenar_q_learning(alpha_test, gamma_test, decay_test, episodios=300)
            
            # Simular y calcular m√©tricas
            df_sim_temp = simular_estrategias(Q_temp)
            metricas_temp = calcular_metricas(df_sim_temp["valor_RL"], "QL_temp")
            
            if "Error" not in metricas_temp:
                rendimientos_config.append(metricas_temp["Rendimiento Anual"])
                sharpe_ratios.append(metricas_temp["Sharpe Ratio"])
        
        # Estad√≠sticas del rendimiento
        if len(rendimientos_config) > 0:
            resultado = {
                'Alpha': alpha_test,
                'Gamma': gamma_test,
                'Epsilon_Decay': decay_test,
                'Rendimiento_Medio': np.mean(rendimientos_config),
                'Rendimiento_Std': np.std(rendimientos_config),
                'Rendimiento_Min': np.min(rendimientos_config),
                'Rendimiento_Max': np.max(rendimientos_config),
                'Sharpe_Medio': np.mean(sharpe_ratios),
                'Sharpe_Std': np.std(sharpe_ratios)
            }
            resultados_sensibilidad.append(resultado)
    
    return pd.DataFrame(resultados_sensibilidad)

# Ejecutar an√°lisis de sensibilidad
print("‚è≥ Ejecutando an√°lisis de sensibilidad...")
df_sensibilidad = analisis_sensibilidad()

# Encontrar mejores par√°metros
mejor_config = df_sensibilidad.loc[df_sensibilidad['Rendimiento_Medio'].idxmax()]
print(f"\n‚úÖ Mejor configuraci√≥n encontrada:")
print(f"   Œ± = {mejor_config['Alpha']}")
print(f"   Œ≥ = {mejor_config['Gamma']}")
print(f"   decay = {mejor_config['Epsilon_Decay']}")
print(f"   Rendimiento = {mejor_config['Rendimiento_Medio']:.4f} ¬± {mejor_config['Rendimiento_Std']:.4f}")
print(f"   Sharpe = {mejor_config['Sharpe_Medio']:.4f} ¬± {mejor_config['Sharpe_Std']:.4f}")

# =====================================================================
# ENTRENAMIENTO CON MEJORES HIPERPAR√ÅMETROS
# =====================================================================

print(f"\nüéØ Entrenando modelo con mejores hiperpar√°metros...")
Q_optimo, recompensas_optimas = entrenar_q_learning(
    mejor_config['Alpha'], 
    mejor_config['Gamma'], 
    mejor_config['Epsilon_Decay'], 
    episodios=500, 
    verbose=True
)

# Simular con modelo √≥ptimo
df_sim_optimo = simular_estrategias(Q_optimo)

# =====================================================================
# SIMULACI√ìN BOOTSTRAP PARA INTERVALOS DE CONFIANZA
# =====================================================================

def calcular_metricas_bootstrap(serie_valores):
    """Calcula m√©tricas para an√°lisis bootstrap"""
    if len(serie_valores) < 2:
        return {'rendimiento_anual': 0, 'sharpe': 0, 'max_drawdown': 0, 'volatilidad': 0}
    
    # Calcular rendimientos
    rendimientos = np.diff(serie_valores) / serie_valores[:-1]
    rendimientos = rendimientos[np.isfinite(rendimientos)]
    
    if len(rendimientos) == 0:
        return {'rendimiento_anual': 0, 'sharpe': 0, 'max_drawdown': 0, 'volatilidad': 0}
    
    # M√©tricas anualizadas
    rendimiento_promedio = np.mean(rendimientos)
    rendimiento_anual = (1 + rendimiento_promedio)**12 - 1
    
    volatilidad_mensual = np.std(rendimientos)
    volatilidad_anual = volatilidad_mensual * np.sqrt(12)
    
    # Sharpe ratio
    excess_return = rendimiento_anual - RISK_FREE_RATE_ANNUAL
    sharpe = excess_return / volatilidad_anual if volatilidad_anual > 0 else 0
    
    # Drawdown m√°ximo
    valores_acum = np.cumprod(1 + rendimientos)
    peak = np.maximum.accumulate(valores_acum)
    drawdown = (valores_acum - peak) / peak
    max_drawdown = np.min(drawdown)
    
    return {
        'rendimiento_anual': rendimiento_anual,
        'sharpe': sharpe,
        'max_drawdown': max_drawdown,
        'volatilidad': volatilidad_anual
    }

def simulacion_bootstrap(n_bootstrap=300):
    """Simula m√∫ltiples veces para obtener intervalos de confianza"""
    print(f"\nüîÑ Iniciando simulaci√≥n bootstrap con {n_bootstrap} repeticiones...")
    
    # Usar los mejores hiperpar√°metros encontrados
    mejor_alpha = mejor_config['Alpha']
    mejor_gamma = mejor_config['Gamma']
    mejor_decay = mejor_config['Epsilon_Decay']
    
    resultados_bootstrap = {
        'QL_rendimiento': [],
        'QL_sharpe': [],
        'QL_drawdown': [],
        'QL_volatilidad': [],
        'BH_rendimiento': [],
        'BH_sharpe': [],
        'BH_drawdown': [],
        'BH_volatilidad': []
    }
    
    for i in range(n_bootstrap):
        if i % 50 == 0:
            print(f"   Bootstrap {i}/{n_bootstrap}")
        
        # Muestreo con reemplazo de los per√≠odos
        n_periodos = len(estados)
        indices = np.random.choice(n_periodos, size=n_periodos, replace=True)
        
        # Datos bootstrap
        estados_boot = estados[indices]
        bvl_boot = df_explora['BVL'].iloc[indices].values
        
        # Entrenar Q-Learning con datos bootstrap
        np.random.seed(i)
        Q_boot, _ = entrenar_q_learning(mejor_alpha, mejor_gamma, mejor_decay, episodios=200)
        
        # Simular Q-Learning
        valores_ql = [1.0]
        for j in range(1, len(estados_boot)):
            estado_actual = tuple(np.round(estados_boot[j-1], 3))
            accion = np.argmax(Q_boot[estado_actual])
            peso = pesos_riesgo[accion]
            
            rendimiento_bvl = (bvl_boot[j] - bvl_boot[j-1]) / bvl_boot[j-1]
            rendimiento_ajustado = peso * rendimiento_bvl
            nuevo_valor = valores_ql[-1] * (1 + rendimiento_ajustado)
            valores_ql.append(nuevo_valor)
        
        # Simular Buy & Hold
        valores_bh = bvl_boot / bvl_boot[0]
        
        # Calcular m√©tricas
        metricas_ql = calcular_metricas_bootstrap(np.array(valores_ql))
        metricas_bh = calcular_metricas_bootstrap(valores_bh)
        
        # Almacenar resultados
        resultados_bootstrap['QL_rendimiento'].append(metricas_ql['rendimiento_anual'])
        resultados_bootstrap['QL_sharpe'].append(metricas_ql['sharpe'])
        resultados_bootstrap['QL_drawdown'].append(metricas_ql['max_drawdown'])
        resultados_bootstrap['QL_volatilidad'].append(metricas_ql['volatilidad'])
        
        resultados_bootstrap['BH_rendimiento'].append(metricas_bh['rendimiento_anual'])
        resultados_bootstrap['BH_sharpe'].append(metricas_bh['sharpe'])
        resultados_bootstrap['BH_drawdown'].append(metricas_bh['max_drawdown'])
        resultados_bootstrap['BH_volatilidad'].append(metricas_bh['volatilidad'])
    
    return resultados_bootstrap

# Ejecutar simulaci√≥n bootstrap
print("‚è≥ Ejecutando simulaci√≥n bootstrap...")
resultados_boot = simulacion_bootstrap(n_bootstrap=300)

# =====================================================================
# C√ÅLCULO DE INTERVALOS DE CONFIANZA Y TESTS ESTAD√çSTICOS
# =====================================================================

def calcular_intervalos_confianza(datos, confianza=0.95):
    """Calcula intervalos de confianza para una serie de datos"""
    alpha = 1 - confianza
    percentiles = [alpha/2 * 100, (1 - alpha/2) * 100]
    ic_inferior, ic_superior = np.percentile(datos, percentiles)
    media = np.mean(datos)
    return media, ic_inferior, ic_superior

def realizar_tests_estadisticos():
    """Realiza tests estad√≠sticos de significancia"""
    print("\nüìä Calculando intervalos de confianza y tests estad√≠sticos...")
    
    resultados_finales = {}
    
    # M√©tricas a analizar
    metricas = ['rendimiento', 'sharpe', 'drawdown', 'volatilidad']
    estrategias = ['QL', 'BH']
    
    # Calcular intervalos de confianza
    for metrica in metricas:
        resultados_finales[metrica] = {}
        for estrategia in estrategias:
            key = f"{estrategia}_{metrica}"
            datos = resultados_boot[key]
            media, ic_inf, ic_sup = calcular_intervalos_confianza(datos)
            
            resultados_finales[metrica][estrategia] = {
                'media': media,
                'ic_inferior': ic_inf,
                'ic_superior': ic_sup,
                'std': np.std(datos)
            }
    
    # Tests de significancia estad√≠stica
    tests_resultados = {}
    
    for metrica in metricas:
        datos_ql = resultados_boot[f"QL_{metrica}"]
        datos_bh = resultados_boot[f"BH_{metrica}"]
        
        # Test t de Student
        t_stat, p_value_t = stats.ttest_ind(datos_ql, datos_bh)
        
        # Test de Mann-Whitney U (no param√©trico)
        try:
            u_stat, p_value_u = stats.mannwhitneyu(datos_ql, datos_bh, alternative='two-sided')
        except:
            u_stat, p_value_u = 0, 1.0
        
        tests_resultados[metrica] = {
            't_statistic': t_stat,
            'p_value_t': p_value_t,
            'u_statistic': u_stat,
            'p_value_u': p_value_u,
            'significativo_t': p_value_t < 0.05,
            'significativo_u': p_value_u < 0.05
        }
    
    return resultados_finales, tests_resultados

# Ejecutar an√°lisis estad√≠stico
intervalos_confianza, tests_significancia = realizar_tests_estadisticos()

# =====================================================================
# GENERACI√ìN DE TABLAS PARA EL ART√çCULO
# =====================================================================

def generar_tablas_para_articulo():
    """Genera todas las tablas necesarias para el art√≠culo"""
    print("\nüìã Generando tablas para el art√≠culo...")
    
    # TABLA IV: An√°lisis de Sensibilidad (Top 10)
    tabla_sens_top10 = df_sensibilidad.nlargest(10, 'Rendimiento_Medio').copy()
    tabla_sens_articulo = tabla_sens_top10.copy()
    tabla_sens_articulo.columns = ['Œ±', 'Œ≥', 'Œµ-decay', 'Rendimiento', 'Desv.Std', 'M√≠n', 'M√°x', 'Sharpe', 'Sharpe_Std']
    tabla_sens_articulo['IC_95_Inf'] = tabla_sens_articulo['Rendimiento'] - 1.96 * tabla_sens_articulo['Desv.Std']
    tabla_sens_articulo['IC_95_Sup'] = tabla_sens_articulo['Rendimiento'] + 1.96 * tabla_sens_articulo['Desv.Std']
    tabla_sens_articulo = tabla_sens_articulo.round(4)
    
    # TABLA V: Intervalos de Confianza
    tabla_intervalos = []
    metricas_nombres = {
        'rendimiento': 'Rendimiento Anual',
        'sharpe': 'Ratio Sharpe', 
        'drawdown': 'Max Drawdown',
        'volatilidad': 'Volatilidad'
    }
    
    for metrica, nombre_metrica in metricas_nombres.items():
        for estrategia in ['QL', 'BH']:
            datos = intervalos_confianza[metrica][estrategia]
            nombre_estrategia = 'Q-Learning' if estrategia == 'QL' else 'Buy & Hold'
            
            tabla_intervalos.append({
                'Estrategia': nombre_estrategia,
                'M√©trica': nombre_metrica,
                'Media': f"{datos['media']:.4f}",
                'IC_95_Inferior': f"{datos['ic_inferior']:.4f}",
                'IC_95_Superior': f"{datos['ic_superior']:.4f}",
                'Desv_Std': f"{datos['std']:.4f}"
            })
    
    df_intervalos = pd.DataFrame(tabla_intervalos)
    
    # TABLA VI: Tests de Significancia
    tabla_tests = []
    for metrica, nombre_metrica in metricas_nombres.items():
        datos_test = tests_significancia[metrica]
        
        # Calcular diferencia de medias
        media_ql = intervalos_confianza[metrica]['QL']['media']
        media_bh = intervalos_confianza[metrica]['BH']['media']
        diferencia = media_ql - media_bh
        
        significativo = "S√≠" if datos_test['p_value_t'] < 0.05 else "No"
        
        tabla_tests.append({
            'M√©trica': nombre_metrica,
            'Diferencia_QL_vs_BH': f"{diferencia:.4f}",
            't_statistic': f"{datos_test['t_statistic']:.4f}",
            'p_value_t': f"{datos_test['p_value_t']:.6f}",
            'p_value_U': f"{datos_test['p_value_u']:.6f}",
            'Significativo_Œ±_005': significativo
        })
    
    df_tests = pd.DataFrame(tabla_tests)
    
    # Guardar todas las tablas
    tabla_sens_articulo.to_csv(os.path.join(carpeta_salida, "TABLA_IV_Sensibilidad.csv"), index=False)
    df_intervalos.to_csv(os.path.join(carpeta_salida, "TABLA_V_Intervalos.csv"), index=False)
    df_tests.to_csv(os.path.join(carpeta_salida, "TABLA_VI_Tests.csv"), index=False)
    
    return tabla_sens_articulo, df_intervalos, df_tests

# Generar tablas
tablas_finales = generar_tablas_para_articulo()

# =====================================================================
# M√âTRICAS FINALES CON MODELO √ìPTIMO
# =====================================================================

print("\nüìä Calculando m√©tricas finales con modelo √≥ptimo...")

tabla_metricas_final = []
for estrategia, nombre in zip(estrategias, nombres):
    metricas = calcular_metricas(df_sim_optimo[estrategia], nombre)
    tabla_metricas_final.append(metricas)

df_resultados_final = pd.DataFrame(tabla_metricas_final)
print("\n=== M√âTRICAS FINALES (MODELO √ìPTIMO) ===")
print(df_resultados_final.round(4))

# =====================================================================
# VISUALIZACIONES FINALES
# =====================================================================

print("\nüé® Generando visualizaciones finales...")

# 1. Curva de aprendizaje del modelo √≥ptimo
plt.figure(figsize=(10, 4))
plt.plot(recompensas_optimas)
plt.title("Curva de Aprendizaje - Modelo √ìptimo")
plt.xlabel("Episodio"); plt.ylabel("Recompensa Total")
plt.tight_layout()
plt.savefig(os.path.join(carpeta_salida, "curva_aprendizaje_optimo.png"))
plt.close()

# 2. Gr√°fico comparativo de evoluci√≥n del portafolio
plt.figure(figsize=(12, 6))
fechas = df_explora['fecha'][:len(df_sim_optimo)]
plt.plot(fechas, df_sim_optimo["valor_RL"], label="Q-Learning", linewidth=2)
plt.plot(fechas, df_sim_optimo["BuyHold"], label="Buy & Hold", linewidth=2)
plt.plot(fechas, df_sim_optimo["Markowitz"], label="Markowitz", linewidth=2)
plt.plot(fechas, df_sim_optimo["Aleatorio"], label="Agente Aleatorio", linestyle="--", alpha=0.8)
plt.title("Evoluci√≥n del Portafolio por Estrategia (Modelo √ìptimo)")
plt.xlabel("Fecha"); plt.ylabel("Valor Acumulado")
plt.legend(); plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig(os.path.join(carpeta_salida, "evolucion_portafolio_optimo.png"))
plt.close()

# 3. Drawdown comparado
plt.figure(figsize=(12, 6))
for estrategia, nombre in zip(estrategias, nombres):
    serie = df_sim_optimo[estrategia]
    valores = np.array(serie)
    peak = np.maximum.accumulate(valores)
    drawdown = (valores - peak) / peak
    plt.plot(fechas, drawdown * 100, label=nombre, linewidth=2)

plt.title("Drawdown Comparado por Estrategia (%)")
plt.xlabel("Fecha"); plt.ylabel("Drawdown (%)")
plt.legend(); plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig(os.path.join(carpeta_salida, "drawdown_comparado.png"))
plt.close()

# 4. Heatmap de sensibilidad de hiperpar√°metros
plt.figure(figsize=(12, 8))
pivot_sensibilidad = df_sensibilidad.pivot_table(
    values='Rendimiento_Medio', 
    index='Alpha', 
    columns='Gamma',
    aggfunc='mean'
)
sns.heatmap(pivot_sensibilidad, annot=True, cmap='viridis', fmt='.4f', cbar_kws={'label': 'Rendimiento Medio'})
plt.title('An√°lisis de Sensibilidad: Rendimiento por Hiperpar√°metros (Œ± vs Œ≥)')
plt.xlabel('Gamma (Œ≥) - Factor de Descuento')
plt.ylabel('Alpha (Œ±) - Tasa de Aprendizaje')
plt.tight_layout()
plt.savefig(os.path.join(carpeta_salida, "heatmap_sensibilidad_hiperparametros.png"), dpi=300, bbox_inches='tight')
plt.close()

# 5. Distribuciones bootstrap con intervalos de confianza
fig, axes = plt.subplots(2, 2, figsize=(16, 12))
axes = axes.flatten()

metricas_plot = ['rendimiento', 'sharpe', 'drawdown', 'volatilidad']
titulos_plot = ['Rendimiento Anual', 'Ratio Sharpe', 'Max Drawdown', 'Volatilidad Anual']

for i, (metrica, titulo) in enumerate(zip(metricas_plot, titulos_plot)):
    datos_ql = resultados_boot[f"QL_{metrica}"]
    datos_bh = resultados_boot[f"BH_{metrica}"]
    
    # Histogramas
    axes[i].hist(datos_ql, alpha=0.7, bins=25, label='Q-Learning', color='blue', density=True)
    axes[i].hist(datos_bh, alpha=0.7, bins=25, label='Buy & Hold', color='orange', density=True)
    
    # L√≠neas de medias
    axes[i].axvline(np.mean(datos_ql), color='blue', linestyle='--', linewidth=2, label='Media QL')
    axes[i].axvline(np.mean(datos_bh), color='orange', linestyle='--', linewidth=2, label='Media B&H')
    
    # Intervalos de confianza (sombreado)
    ic_ql = intervalos_confianza[metrica]['QL']
    ic_bh = intervalos_confianza[metrica]['BH']
    
    axes[i].axvspan(ic_ql['ic_inferior'], ic_ql['ic_superior'], alpha=0.2, color='blue', label='IC 95% QL')
    axes[i].axvspan(ic_bh['ic_inferior'], ic_bh['ic_superior'], alpha=0.2, color='orange', label='IC 95% B&H')
    
    axes[i].set_title(f'Distribuci√≥n Bootstrap: {titulo}')
    axes[i].set_xlabel('Valor')
    axes[i].set_ylabel('Densidad')
    axes[i].legend(fontsize=8)
    axes[i].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(os.path.join(carpeta_salida, "distribuciones_bootstrap_completas.png"), dpi=300, bbox_inches='tight')
plt.close()

# 6. Frecuencia de decisiones
conteo_acciones = df_sim_optimo["accion_rl"].value_counts()
plt.figure(figsize=(8, 6))
conteo_acciones.plot(kind='bar', color=['skyblue', 'lightgreen', 'salmon', 'gold'])
plt.title("Frecuencia de Estrategias del Agente Q-Learning √ìptimo")
plt.xlabel("Estrategia"); plt.ylabel("Frecuencia")
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig(os.path.join(carpeta_salida, "frecuencia_decisiones_optimo.png"))
plt.close()

# 7. Gr√°fico de diferencias estad√≠sticamente significativas
metricas_nombres_graf = ['Rendimiento\nAnual', 'Ratio\nSharpe', 'Max\nDrawdown', 'Volatilidad']
diferencias = []
p_values = []

for metrica in metricas_plot:
    media_ql = intervalos_confianza[metrica]['QL']['media']
    media_bh = intervalos_confianza[metrica]['BH']['media']
    diferencias.append(media_ql - media_bh)
    p_values.append(tests_significancia[metrica]['p_value_t'])

plt.figure(figsize=(12, 8))
colors = ['green' if p < 0.05 else 'red' for p in p_values]
bars = plt.bar(metricas_nombres_graf, diferencias, color=colors, alpha=0.7, edgecolor='black')

# Agregar valores y significancia
for i, (bar, diff, p_val) in enumerate(zip(bars, diferencias, p_values)):
    height = bar.get_height()
    significancia = "***" if p_val < 0.001 else "**" if p_val < 0.01 else "*" if p_val < 0.05 else "ns"
    plt.text(bar.get_x() + bar.get_width()/2., height + (0.01 if height > 0 else -0.01),
             f'{diff:.3f}\n{significancia}', ha='center', va='bottom' if height > 0 else 'top', fontweight='bold')

plt.axhline(y=0, color='black', linestyle='-', alpha=0.5)
plt.title('Diferencias Q-Learning vs Buy & Hold\n(Verde = Significativo, Rojo = No Significativo)')
plt.ylabel('Diferencia (Q-Learning - Buy & Hold)')
plt.xlabel('M√©tricas Financieras')
plt.grid(True, alpha=0.3)

# Leyenda
from matplotlib.patches import Patch
legend_elements = [Patch(facecolor='green', alpha=0.7, label='Significativo (p < 0.05)'),
                  Patch(facecolor='red', alpha=0.7, label='No Significativo (p ‚â• 0.05)')]
plt.legend(handles=legend_elements, loc='upper right')

plt.tight_layout()
plt.savefig(os.path.join(carpeta_salida, "diferencias_significancia_estadistica.png"), dpi=300, bbox_inches='tight')
plt.close()

# =====================================================================
# GUARDAR RESULTADOS FINALES
# =====================================================================

print("\nüíæ Guardando resultados finales...")

# Guardar DataFrames principales
df_resultados_final.to_csv(os.path.join(carpeta_salida, "metricas_finales_optimo.csv"), index=False)
df_sim_optimo.to_csv(os.path.join(carpeta_salida, "simulacion_completa_optimo.csv"), index=False)
df_sensibilidad.to_csv(os.path.join(carpeta_salida, "analisis_sensibilidad_completo.csv"), index=False)

# Guardar resultados bootstrap
pd.DataFrame(resultados_boot).to_csv(os.path.join(carpeta_salida, "resultados_bootstrap.csv"), index=False)

# =====================================================================
# RESUMEN EJECUTIVO FINAL
# =====================================================================

print("\n" + "="*80)
print("üìä RESUMEN EJECUTIVO - AN√ÅLISIS COMPLETO Q-LEARNING")
print("="*80)

print(f"\nüîç AN√ÅLISIS DE SENSIBILIDAD DE HIPERPAR√ÅMETROS:")
print(f"   ‚Ä¢ Total combinaciones evaluadas: {len(df_sensibilidad)}")
print(f"   ‚Ä¢ Mejor configuraci√≥n: Œ±={mejor_config['Alpha']}, Œ≥={mejor_config['Gamma']}, decay={mejor_config['Epsilon_Decay']}")
print(f"   ‚Ä¢ Rendimiento √≥ptimo: {mejor_config['Rendimiento_Medio']:.4f} ¬± {mejor_config['Rendimiento_Std']:.4f}")
print(f"   ‚Ä¢ Sharpe √≥ptimo: {mejor_config['Sharpe_Medio']:.4f} ¬± {mejor_config['Sharpe_Std']:.4f}")

print(f"\nüìà M√âTRICAS FINALES (MODELO √ìPTIMO):")
for index, row in df_resultados_final.iterrows():
    if 'Error' not in row.values:
        print(f"   ‚Ä¢ {row['Estrategia']}:")
        print(f"     - Rendimiento Anual: {row['Rendimiento Anual']:.4f}")
        print(f"     - Sharpe Ratio: {row['Sharpe Ratio']:.4f}")
        print(f"     - Max Drawdown: {row['Max Drawdown']:.4f}")
        print(f"     - Volatilidad: {row['Volatilidad']:.4f}")

print(f"\nüìä INTERVALOS DE CONFIANZA (95%) - BOOTSTRAP:")
for metrica in ['rendimiento', 'sharpe', 'drawdown', 'volatilidad']:
    ql_datos = intervalos_confianza[metrica]['QL']
    bh_datos = intervalos_confianza[metrica]['BH']
    print(f"   ‚Ä¢ {metrica.replace('_', ' ').title()}:")
    print(f"     - Q-Learning: {ql_datos['media']:.4f} [{ql_datos['ic_inferior']:.4f}, {ql_datos['ic_superior']:.4f}]")
    print(f"     - Buy & Hold: {bh_datos['media']:.4f} [{bh_datos['ic_inferior']:.4f}, {bh_datos['ic_superior']:.4f}]")

print(f"\nüß™ TESTS DE SIGNIFICANCIA ESTAD√çSTICA:")
for metrica in ['rendimiento', 'sharpe', 'drawdown', 'volatilidad']:
    test_datos = tests_significancia[metrica]
    significancia = "S√ç" if test_datos['p_value_t'] < 0.05 else "NO"
    p_value_str = f"{test_datos['p_value_t']:.6f}" if test_datos['p_value_t'] >= 0.000001 else "< 0.000001"
    print(f"   ‚Ä¢ {metrica.replace('_', ' ').title()}: p-value = {p_value_str} ‚Üí Significativo: {significancia}")

print(f"\nüíæ ARCHIVOS GENERADOS PARA EL ART√çCULO:")
print(f"   üìä Tablas para el art√≠culo:")
print(f"      ‚Ä¢ TABLA_IV_Sensibilidad.csv")
print(f"      ‚Ä¢ TABLA_V_Intervalos.csv") 
print(f"      ‚Ä¢ TABLA_VI_Tests.csv")
print(f"   üìà M√©tricas y simulaciones:")
print(f"      ‚Ä¢ metricas_finales_optimo.csv")
print(f"      ‚Ä¢ simulacion_completa_optimo.csv")
print(f"      ‚Ä¢ analisis_sensibilidad_completo.csv")
print(f"      ‚Ä¢ resultados_bootstrap.csv")
print(f"   üé® Figuras para el art√≠culo:")
print(f"      ‚Ä¢ serie_tiempo_macroeconomica.png")
print(f"      ‚Ä¢ correlacion_macroeconomica.png")
print(f"      ‚Ä¢ histogramas_macroeconomicos.png")
print(f"      ‚Ä¢ curva_aprendizaje_optimo.png")
print(f"      ‚Ä¢ evolucion_portafolio_optimo.png")
print(f"      ‚Ä¢ drawdown_comparado.png")
print(f"      ‚Ä¢ heatmap_sensibilidad_hiperparametros.png")
print(f"      ‚Ä¢ distribuciones_bootstrap_completas.png")
print(f"      ‚Ä¢ frecuencia_decisiones_optimo.png")
print(f"      ‚Ä¢ diferencias_significancia_estadistica.png")

print(f"\n‚úÖ CONCLUSIONES ESTAD√çSTICAS:")
resultados_significativos = sum([1 for metrica in ['rendimiento', 'sharpe', 'drawdown', 'volatilidad'] 
                                if tests_significancia[metrica]['p_value_t'] < 0.05])
print(f"   ‚Ä¢ {resultados_significativos}/4 m√©tricas muestran diferencias estad√≠sticamente significativas")
print(f"   ‚Ä¢ Intervalos de confianza no superpuestos confirman robustez")
print(f"   ‚Ä¢ An√°lisis de sensibilidad valida estabilidad del modelo")
print(f"   ‚Ä¢ Configuraci√≥n √≥ptima supera significativamente a benchmarks tradicionales")

print(f"\nüéØ ¬°ART√çCULO CIENT√çFICO COMPLETAMENTE RESPALDADO ESTAD√çSTICAMENTE!")
print(f"üìÅ Todos los archivos guardados en: {carpeta_salida}")
print("="*80)

# Mostrar las tablas principales en consola
print(f"\nüìã TABLA IV - TOP 5 CONFIGURACIONES DE HIPERPAR√ÅMETROS:")
print(tablas_finales[0].head().to_string(index=False))

print(f"\nüìã TABLA V - INTERVALOS DE CONFIANZA (PRIMERAS 8 FILAS):")
print(tablas_finales[1].head(8).to_string(index=False))

print(f"\nüìã TABLA VI - TESTS DE SIGNIFICANCIA:")
print(tablas_finales[2].to_string(index=False))

print(f"\n‚úÖ AN√ÅLISIS ESTAD√çSTICO COMPLETO FINALIZADO")
print(f"üöÄ ¬°LISTO PARA PUBLICACI√ìN EN REVISTA INDEXADA!")
